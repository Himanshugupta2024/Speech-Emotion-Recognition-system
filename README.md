# Speech Emotion Recognition system
 
# Speech Emotion Recognition & Speaker Identification

## Description

This project implements a Speech Emotion Recognition (SER) and Speaker Identification system using audio processing and simulated deep learning models. The system can analyze audio recordings to detect emotions and identify speakers through a user-friendly web interface.

### Key Features

- **Emotion Detection**: Analyzes audio to identify 8 emotions (Neutral, Happy, Sad, Angry, Fearful, Disgusted, Surprised, Calm)
- **Audio Feature Extraction**: Extracts and visualizes waveform, spectrogram, MFCC, pitch contour, energy, and zero crossing rate
- **Interactive Web Interface**: Record audio directly through the browser or upload audio files
- **Real-time Analysis**: Process audio files with instant visual feedback
- **Speaker Management**: Register and identify different speakers (simulated functionality)
- **Comprehensive Visualizations**: View detailed audio analysis through an intuitive dashboard

### Technologies Used

- **Backend**: Python, Flask, Librosa (audio processing)
- **Frontend**: HTML, CSS, JavaScript, Bootstrap
- **Audio Processing**: Matplotlib for visualization, NumPy for numerical operations
- **Architecture Diagrams**: Visual representations of CNN, LSTM, and hybrid model architectures

This system provides a foundational framework for speech emotion recognition that can be extended with actual trained machine learning models for more accurate emotion detection and speaker identification in real-world applications.
